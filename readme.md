# ğŸ“˜ Learning Probability Density Functions using a Parameterized Non-Linear Model

This repository presents an implementation for learning a probability density function (PDF) using a parameterized transformation applied to real-world air quality data. The parameters of the PDF are estimated using Maximum Likelihood Estimation (MLE).

## ğŸ“Œ Objective

The objectives of this assignment are:
- To apply a parameterized non-linear transformation to the NOâ‚‚ feature
- To learn the parameters of a given probability density function
- To estimate Î¼, Î», and c from real data
- To visualize and analyze the learned probability distribution

## ğŸ“ Dataset Information

- Dataset: India Air Quality Data  
- Source: Kaggle  
- Feature Used: NOâ‚‚  
- Valid Samples: ~4.2 lakh (after removing missing values)

Only numerical NOâ‚‚ values are used in this work.

## ğŸ”¢ Parameterized Transformation

The transformation parameters are derived from a university roll number, which is intentionally hidden for privacy.

ar = 0.05 Ã— (r mod 7)  
br = 0.3 Ã— (r mod 5 + 1)

For the parameter values used in this work:
- ar = 0  
- br = 0.3  

## ğŸ”„ Data Transformation

The transformation function is:

z = x + ar Â· sin(br Â· x)

Since ar = 0, the transformation simplifies to:

z = x

Thus, the transformed variable is identical to the original NOâ‚‚ values for this parameter setting.

## ğŸ“ Probability Density Function

The probability density function to be learned is:

pÌ‚(z) = c Â· exp(âˆ’Î»(z âˆ’ Î¼)Â²)

Where:
- Î¼ is the mean of the distribution  
- Î» controls the spread  
- c is the normalization constant  

This represents a Gaussian-type distribution.

## ğŸ§® Parameter Estimation Methodology

The parameters are estimated using Maximum Likelihood Estimation (MLE).  
For a Gaussian-type distribution, MLE provides closed-form solutions:

Î¼ = (1/N) Î£ záµ¢  
ÏƒÂ² = (1/N) Î£ (záµ¢ âˆ’ Î¼)Â²  
Î» = 1 / (2ÏƒÂ²)  
c = âˆš(Î» / Ï€)

This approach is mathematically optimal, computationally efficient, and numerically stable.

## ğŸ“Š Results

Estimated PDF Parameters:

| Parameter | Value (Approx.) |
|----------|----------------|
| Î¼        | 25.81          |
| Î»        | 0.00146        |
| c        | 0.02156        |

These parameters define the learned probability distribution of NOâ‚‚ concentrations.

## ğŸ“ˆ Result Visualization

The figure below shows the histogram of NOâ‚‚ values along with the estimated probability density function.

![Histogram and Estimated PDF](pdf_plot.png)

### Interpretation

- The histogram represents the empirical distribution of the data  
- The estimated PDF is a smooth Gaussian-like curve  
- The PDF closely follows the overall trend of the data  
- Minor deviations are expected due to real-world data skewness  

## ğŸ“ Observations

- The transformation reduces to identity for the chosen parameters  
- The methodology remains valid for other parameter values  
- The learned PDF is properly normalized  
- No iterative optimization or machine learning model is required  

## âœ… Conclusion

This project demonstrates real-world data preprocessing, parameterized feature transformation, analytical probability density estimation, and statistically sound modeling using Maximum Likelihood Estimation. The approach is simple, efficient, and suitable for large-scale datasets.

## ğŸ“‚ Repository Structure

1. main.py  
2. pdf_plot.png 
3. README.md 
